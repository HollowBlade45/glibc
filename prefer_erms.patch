diff -purN glibc-2.25/sysdeps/x86_64.org/multiarch/memcpy.S glibc-2.25/sysdeps/x86_64/multiarch/memcpy.S
--- glibc-2.25/sysdeps/x86_64.org/multiarch/memcpy.S	2017-02-05 15:28:43.000000000 +0000
+++ glibc-2.25/sysdeps/x86_64/multiarch/memcpy.S	2017-04-01 17:26:50.653481909 +0000
@@ -33,7 +33,7 @@ ENTRY(__new_memcpy)
 	HAS_ARCH_FEATURE (Prefer_ERMS)
 	jnz	2f
 	HAS_ARCH_FEATURE (AVX512F_Usable)
-	jz	1f
+	jmp	1f
 	lea	__memcpy_avx512_no_vzeroupper(%rip), %RAX_LP
 	HAS_ARCH_FEATURE (Prefer_No_VZEROUPPER)
 	jnz	2f
@@ -44,7 +44,7 @@ ENTRY(__new_memcpy)
 	ret
 1:	lea	__memcpy_avx_unaligned(%rip), %RAX_LP
 	HAS_ARCH_FEATURE (AVX_Fast_Unaligned_Load)
-	jz	L(Fast_Unaligned_Load)
+	jmp	L(Fast_Unaligned_Load)
 	HAS_CPU_FEATURE (ERMS)
 	jz	2f
 	lea	__memcpy_avx_unaligned_erms(%rip), %RAX_LP
diff -purN glibc-2.25/sysdeps/x86_64.org/multiarch/memset.S glibc-2.25/sysdeps/x86_64/multiarch/memset.S
--- glibc-2.25/sysdeps/x86_64.org/multiarch/memset.S	2017-02-05 15:28:43.000000000 +0000
+++ glibc-2.25/sysdeps/x86_64/multiarch/memset.S	2017-04-01 17:25:22.943811240 +0000
@@ -35,7 +35,7 @@ ENTRY(memset)
 	lea	__memset_sse2_unaligned(%rip), %RAX_LP
 1:
 	HAS_ARCH_FEATURE (AVX2_Usable)
-	jz	2f
+	jmp	2f
 	lea	__memset_avx2_unaligned_erms(%rip), %RAX_LP
 	HAS_CPU_FEATURE (ERMS)
 	jnz	L(AVX512F)
diff -purN glibc-2.25/sysdeps/x86_64.org/multiarch/memset-vec-unaligned-erms.S glibc-2.25/sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S
--- glibc-2.25/sysdeps/x86_64.org/multiarch/memset-vec-unaligned-erms.S	2017-02-05 15:28:43.000000000 +0000
+++ glibc-2.25/sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S	2017-04-01 17:27:29.029855951 +0000
@@ -102,6 +102,10 @@ L(entry_from_bzero):
 #if defined USE_MULTIARCH && IS_IN (libc)
 END (MEMSET_SYMBOL (__memset, unaligned))
 
+L(stosb):
+	/* Issue vzeroupper before rep stosb.  */
+	VZEROUPPER
+
 # if VEC_SIZE == 16
 /* Only used to measure performance of REP STOSB.  */
 ENTRY (__memset_erms)
@@ -109,9 +113,6 @@ ENTRY (__memset_erms)
 /* Provide a symbol to debugger.  */
 ENTRY (MEMSET_SYMBOL (__memset, erms))
 # endif
-L(stosb):
-	/* Issue vzeroupper before rep stosb.  */
-	VZEROUPPER
 	movq	%rdx, %rcx
 	movzbl	%sil, %eax
 	movq	%rdi, %rdx
